{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvs-personalstash/Stambede_Data_Collection/blob/main/Copy_of_stampede_wiki_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install-cell",
        "outputId": "56b47403-3115-4c6d-d572-a88c361f0c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=dd79c4fe11c2a179e582cc62ca5c4d8806c59105beedd94af280d8c50c4a4d7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.9.post2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.43.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.55.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.14.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.8.3)\n",
            "Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m853.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bertopic\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bertopic-0.17.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=0ba3a9182d02fdd8e584306f2cd79f4cda4ffe8335d3f96c1e32bf2689937f17\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia-api beautifulsoup4 requests google\n",
        "!pip install bertopic\n",
        "!pip install wikipedia\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "import-cell",
      "metadata": {
        "id": "import-cell"
      },
      "outputs": [],
      "source": [
        "import wikipediaapi\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from typing import Dict, Any, List\n",
        "import json\n",
        "from urllib.parse import quote_plus\n",
        "import time\n",
        "from googlesearch import search\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from umap import UMAP\n",
        "\n",
        "# Initialize UMAP and BERTopic models once (tweak as needed)\n",
        "umap_model = UMAP(n_neighbors=5, n_components=5, metric='cosine')\n",
        "# Initialize BERTopic model once\n",
        "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
        "#topic_model = BERTopic(vectorizer_model=vectorizer_model, calculate_probabilities=False)\n",
        "topic_model = BERTopic(\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    umap_model=umap_model,\n",
        "    calculate_probabilities=False,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "functions-cell",
      "metadata": {
        "id": "functions-cell"
      },
      "outputs": [],
      "source": [
        "def google_search_wikipedia_article(query, num_results=5, pause_seconds=2.0):\n",
        "    search_query = f\"{query} stampede wikipedia\"\n",
        "    print(f\"Searching for: {search_query}\")\n",
        "\n",
        "    wikipedia_titles = []\n",
        "    try:\n",
        "        for url in search(search_query,\n",
        "                          num=num_results,    # pages per request batch\n",
        "                          stop=num_results,   # total results to retrieve\n",
        "                          pause=pause_seconds # seconds between requests\n",
        "                         ):\n",
        "            if \"wikipedia.org/wiki/\" in url:\n",
        "                print(url)\n",
        "                title = url.split(\"/wiki/\")[-1].replace(\"_\", \" \")\n",
        "                wikipedia_titles.append(title)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Google search: {e}\")\n",
        "        potential_titles = [\n",
        "            f\"{query} stampede\",\n",
        "            f\"{query} crowd crush\",\n",
        "            f\"{query} disaster\",\n",
        "            f\"{query} incident\",\n",
        "        ]\n",
        "        wikipedia_titles = potential_titles\n",
        "\n",
        "    return wikipedia_titles\n",
        "\n",
        "def fetch_wikipedia_article(title):\n",
        "    \"\"\"\n",
        "    Fetch a Wikipedia article by its title.\n",
        "\n",
        "    Args:\n",
        "        title: The title of the Wikipedia article\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with article data or None if not found\n",
        "    \"\"\"\n",
        "    wiki = wikipediaapi.Wikipedia(user_agent='StampedeInfoRetrieval/1.0', language='en')\n",
        "    page = wiki.page(title)\n",
        "\n",
        "    if page.exists():\n",
        "        return {\n",
        "            \"title\": page.title,\n",
        "            \"summary\": page.summary,\n",
        "            \"full_text\": page.text,\n",
        "            \"url\": page.fullurl,\n",
        "            \"categories\": list(page.categories.keys()),\n",
        "            \"links\": list(page.links.keys())\n",
        "        }\n",
        "    return None\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Helper: split long text into chunks\n",
        "def chunk_text(text: str, words_per_chunk: int = 300) -> List[str]:\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i : i + words_per_chunk]) for i in range(0, len(words), words_per_chunk)]\n",
        "\n",
        "# Fallback keyword extractor using TF-IDF\n",
        "def extract_keywords_tfidf(text: str, top_n: int = 10) -> List[str]:\n",
        "    tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=50)\n",
        "    tfidf_matrix = tfidf.fit_transform([text])\n",
        "    scores = zip(tfidf.get_feature_names_out(), tfidf_matrix.toarray().flatten())\n",
        "    sorted_terms = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    return [term for term, score in sorted_terms[:top_n]]\n",
        "\n",
        "\n",
        "def extract_stampede_info(article_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    stampede_info = {\n",
        "        \"title\": article_data.get(\"title\"),\n",
        "        \"summary\": article_data.get(\"summary\"),\n",
        "        \"url\": article_data.get(\"url\"),\n",
        "        \"date\": None,\n",
        "        \"location\": None,\n",
        "        \"casualties\": {\"deaths\": None, \"injuries\": None},\n",
        "        \"cause\": None,\n",
        "        \"keywords\": [],\n",
        "        \"numbers\": [],\n",
        "        \"query\": None\n",
        "    }\n",
        "\n",
        "    # 1. Extract date\n",
        "    date_patterns = [\n",
        "        r\"(?:on|in|during)\\s+([A-Z][a-z]+\\s+\\d{1,2},\\s+\\d{4})\",\n",
        "        r\"(?:on|in|during)\\s+(\\d{1,2}\\s+[A-Z][a-z]+\\s+\\d{4})\",\n",
        "        r\"(?:on|in|during)\\s+([A-Z][a-z]+\\s+\\d{4})\",\n",
        "        r\"(?:on|in|during)\\s+(\\d{4})\",\n",
        "    ]\n",
        "    for pat in date_patterns:\n",
        "        m = re.search(pat, article_data.get(\"summary\", \"\"))\n",
        "        if m:\n",
        "            stampede_info[\"date\"] = m.group(1)\n",
        "            break\n",
        "\n",
        "    # 2. Extract location\n",
        "    location_patterns = [\n",
        "        r\"in\\s+([A-Z][a-z]+(?:,\\s+[A-Z][a-z]+)*)\",\n",
        "        r\"at\\s+([A-Z][a-z]+(?:,\\s+[A-Z][a-z]+)*)\",\n",
        "    ]\n",
        "    for pat in location_patterns:\n",
        "        m = re.search(pat, article_data.get(\"summary\", \"\"))\n",
        "        if m:\n",
        "            stampede_info[\"location\"] = m.group(1)\n",
        "            break\n",
        "\n",
        "    # 3. Extract casualties\n",
        "    for pat in [r\"(\\d+)\\s+(?:people|individuals)\\s+(?:were\\s+)?killed\", r\"(\\d+)\\s+deaths\"]:\n",
        "        m = re.search(pat, article_data.get(\"full_text\", \"\"))\n",
        "        if m:\n",
        "            stampede_info[\"casualties\"][\"deaths\"] = int(m.group(1))\n",
        "            break\n",
        "    for pat in [r\"(\\d+)\\s+(?:people|individuals)\\s+(?:were\\s+)?injured\", r\"(\\d+)\\s+injuries\"]:\n",
        "        m = re.search(pat, article_data.get(\"full_text\", \"\"))\n",
        "        if m:\n",
        "            stampede_info[\"casualties\"][\"injuries\"] = int(m.group(1))\n",
        "            break\n",
        "\n",
        "    # 4. Extract cause snippet\n",
        "    for kw in [\"cause\", \"trigger\", \"due to\", \"led to\"]:\n",
        "        pat = re.compile(f\"({kw}[^.]*\\.)\", re.IGNORECASE)\n",
        "        m = pat.search(article_data.get(\"full_text\", \"\"))\n",
        "        if m:\n",
        "            stampede_info[\"cause\"] = m.group(1).strip()\n",
        "            break\n",
        "\n",
        "    # 5. Aggregate keywords\n",
        "    text = (article_data.get(\"summary\", \"\") + \"\\n\\n\" + article_data.get(\"full_text\", \"\")).strip()\n",
        "    if text:\n",
        "        chunks = chunk_text(text, words_per_chunk=300)\n",
        "        if len(chunks) < 3:\n",
        "            stampede_info[\"keywords\"] = extract_keywords_tfidf(text, top_n=10)\n",
        "        else:\n",
        "            try:\n",
        "                num_chunks = len(chunks)\n",
        "                new_k = max(1, min(num_chunks - 1, umap_model.n_neighbors))\n",
        "                topic_model.umap_model.set_params(n_neighbors=new_k)\n",
        "                topics, _ = topic_model.fit_transform(chunks)\n",
        "                keywords = []\n",
        "                for t in set(topics):\n",
        "                    if t == -1:\n",
        "                        continue\n",
        "                    keywords.extend([kw for kw, _ in topic_model.get_topic(t)[:5]])\n",
        "                seen = set(); deduped = []\n",
        "                for kw in keywords:\n",
        "                    if kw not in seen:\n",
        "                        seen.add(kw); deduped.append(kw)\n",
        "                stampede_info[\"keywords\"] = deduped[:10]\n",
        "            except Exception:\n",
        "                stampede_info[\"keywords\"] = extract_keywords_tfidf(text, top_n=10)\n",
        "\n",
        "    # 6. Extract numeric entities only\n",
        "    doc = nlp(article_data.get(\"full_text\", \"\"))\n",
        "    stampede_info[\"numbers\"] = [ent.text for ent in doc.ents if ent.label_ in [\"CARDINAL\", \"QUANTITY\"]]\n",
        "\n",
        "    # 7. Construct news query\n",
        "    parts: List[str] = []\n",
        "    if stampede_info[\"location\"]:\n",
        "        parts.append(stampede_info[\"location\"])\n",
        "    if stampede_info[\"date\"]:\n",
        "        parts.append(stampede_info[\"date\"])\n",
        "    parts.extend(stampede_info.get(\"keywords\", []))\n",
        "    stampede_info[\"query\"] = \" \".join(parts)\n",
        "\n",
        "    return stampede_info\n",
        "\n",
        "def retrieve_stampede_info(stampede_name):\n",
        "    \"\"\"\n",
        "    Main function to retrieve information about a stampede event.\n",
        "\n",
        "    Args:\n",
        "        stampede_name: Name of the stampede event\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with stampede information or None if not found\n",
        "    \"\"\"\n",
        "    # Step 1: Search for Wikipedia articles related to the stampede\n",
        "    wikipedia_titles = google_search_wikipedia_article(stampede_name)\n",
        "\n",
        "    if not wikipedia_titles:\n",
        "        print(f\"No Wikipedia articles found for '{stampede_name}'\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {len(wikipedia_titles)} potential Wikipedia articles:\")\n",
        "    for i, title in enumerate(wikipedia_titles):\n",
        "        print(f\"  {i+1}. {title}\")\n",
        "\n",
        "    # Step 2: Try to fetch each article until we find one that exists\n",
        "    article_data = None\n",
        "    for title in wikipedia_titles:\n",
        "        print(f\"\\nTrying to fetch article: {title}\")\n",
        "        article_data = fetch_wikipedia_article(title)\n",
        "        if article_data:\n",
        "            print(f\"Successfully retrieved article: {article_data['title']}\")\n",
        "            break\n",
        "\n",
        "    if not article_data:\n",
        "        print(f\"Could not find any valid Wikipedia articles for '{stampede_name}'\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: Extract stampede information from the article\n",
        "    stampede_info = extract_stampede_info(article_data)\n",
        "\n",
        "    return stampede_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "multiple-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "be5bbb385a63426fb32b63d01c6522a5",
            "8d4949d2bd8c415699ace404ace8be40",
            "2cf828d49c0945878a5858ba7745fdf0",
            "ee17c5bcf08c4bd5a6598ca2844f2fa1",
            "49c456e9ed564e3087de2a20e3ed970c",
            "e415ed34109f45c29fac1a6967961973",
            "763e016ba87c40ad86441b30ffa44bba",
            "97de8b7ab0274672b94a393fa0e0f058",
            "3de2d3dd4ad144beac10b7ba6ca5f146",
            "1c5a9b1d243547beafced932b17e8cf5",
            "0f2e79415baf4429a2a2ea65a320ed59",
            "1c2b2b50fd644718a8cf9836073e143c",
            "05893fd988a64ded9e0a88b21779d176",
            "7dbcf36ef14941eea3e27a7c7ac5c49c",
            "9bf82c14a0464102a69a23b95f58829c",
            "0578890f14fa44d2b57e7f70fb0f1296",
            "7523fec743c640d9a2a9c75d9975382f",
            "96b70404f15444fc94db60a0c97e886d",
            "d3fdcf47f0344b7f82ac2a44a2553fa8",
            "9cf88bb9392141abbc9403579f34d2db",
            "f417b91dad59402db4f4bc924cbfa462",
            "707a9974d07f4c308e591bec6aca31c1",
            "9bd286153f7d47fd88c902e3f1a57545",
            "570d1d3c6dba4db4bb6ac1ed49aa8c1f",
            "eee34c15249f4d48a488ab06a460dfd4",
            "55f17cbe3b3a4702b06b8362df4d1505",
            "d610a0afab2b4f0795eb9cef7fc3fadf",
            "1b7b899a06dd46a3be4898ac713780c1",
            "676329798dd445fdb59fecafaaeeef6a",
            "a62957a217534cf3a87c68c80740828e",
            "4bb6adf78f7f4fe097b12ee5312db39b",
            "95d69aa82c744117ba75f5dd290fc6fd",
            "eebdfec5bc674db89add7bf9fea0d054",
            "43081f0912db488fab9325d4e46bf4dc",
            "7cf22fc342db4542a3126f7e10afe5d6",
            "de8015efa43748c08e9aa85545650fff",
            "0da684a3091244f4bc800901f385b205",
            "a8f62e692a71492484eced2bf463b743",
            "172b37699d7b47c2b8e24d6a44b4c97a",
            "0e61463185f34e5cafaa50900160d66e",
            "ea0ad5f724924fcb869a751c052304ed",
            "49e3c5aeb4c44b9c925f19ab8436cab4",
            "d08b6750eb0147b6abe7082087567944",
            "d4ca6d3aebc04f1c83c5d9309366f1d6",
            "4bd5c1f533784f52bc9eff3f4f81ed02",
            "d159a8d8ca4d49baaa737219c77467af",
            "13b82cd5b7584e2bbc8956b5842fec0f",
            "e5fc2e0178b049679db30725652da2b0",
            "a1c51b3fb1ee42d9b6039c76ea8f0798",
            "04be117f3fcc4917a98764641d9244fe",
            "fd4da20daa9a41f4b177e9cfbee5f1a6",
            "2400a67b9f234cf9ac96da5a9e71c246",
            "bc68e85064b34a17ae9cf1568c9ce8a5",
            "5fd10933b6ae4671bd185b6eb7927c49",
            "3ab11e06a5684bbfa861a60cdcac21b6",
            "9d504ec50dd24eda8aae3eacaf2284f5",
            "33a640c72409458eb6029e3f4e4d3667",
            "7f1f490086474874acfedbbebf9e6d6d",
            "2e58f42f05ee4a33ac51ffded7d73333",
            "c0b986846fc14191a9a63e30fbaa37f8",
            "a20210a1b9e34bb78968ff265f408bcd",
            "c869b3cc8d7e49449a5614e5f10e04d1",
            "007d7fb84555441bb4f174e5d2492d24",
            "fe1a1353fec342e58989ee85bbb02ef8",
            "d782715bf86b4df08a29699da7799af3",
            "0913d2df1e004458a7e616a7757971bd",
            "beb152a8bb4041a2bd08a457262de2bd",
            "774594020e58468cae208dfdea5047a7",
            "281346e77dd74a15ad7e31f312bcc9de",
            "aab7258580be425bbd1b31acae1be0a1",
            "6a138b68f3094e48939bfb9cb5f20bf5",
            "cf751d4386ea4e15a6e68b931759ab45",
            "7a7288189afe423f8a315b8890d77a40",
            "30825e9736ad4c8db69ca343e558ef1e",
            "2c440a12cfb441ecbb3adb93731bb7fa",
            "ba40e4a8ba9f42d2872c919c3678697b",
            "f409f1327fa74fe99c4a143744566975",
            "fc7279b9935b457f9547e98d65d5ec5c",
            "cf8ffe7bcad44464a5fec121974af0e7",
            "00c6f00d95d44a18a188109316bdc4b7",
            "24d63bb87aea4f8d952b2645b4b21e10",
            "8b46b61d2b3c4df4936b13b0c49c74df",
            "5892c09303ca4078870476636de40337",
            "acda1c826b6047778728865cdfec1179",
            "f6e85cefb5e5489883fadc52a224d67f",
            "417ccdf9ceab4350b77b48879542958d",
            "4b5d9ec502604db79945297e196578ae",
            "daa715f4bc884b8999820262df3f3563",
            "35f9bec0c42c4a739e9e68eb44aced99",
            "8935d8c4d9954e9a890c33a5045e0722",
            "9d699fa91ac742c5a5a81cb497758ac9",
            "6a9c38691b934048847cee1c82565492",
            "d53ad0f627c041f58808aeb50f6954d5",
            "febb8f56a9dd46b5b9559038abe2d415",
            "84221e02ee614d0091f46ed90d6b1b7f",
            "b85a2055d64f45cc9657afcecd566ca4",
            "be63a64abec9435d8fabd6cd1672ae46",
            "5d40c55f3d7b43f1b0c7e2ec0878a787",
            "1c706263e54146cdbc1721327f14958f",
            "756430fd340a4205ad43cf92602cf6ba",
            "9d3fff46a69942fb9b91eabc3cbec69a",
            "56cf532b14bc4625a1302d452b4f506b",
            "8c98362bc15f4df8ad97b1a68ca00312",
            "40b48e4eac714a1d90152a7384a2938b",
            "7665e96f36ce47c9a321c7df067ade2f",
            "9ef9144f94614496bc0e8eb4f0bd2fb8",
            "97ee57d22f76469c9543a2c8c1b76382",
            "b29db67ceee64e2982edfcb40abbedbd",
            "e76e8d96b2714b3ba60e0e8aa6993510",
            "c2b22928d4e04becaa1f121eb7455985",
            "e2dfa5581b964f9780f9f1da9ea1e0a2",
            "8a60b8c81df344cc88753cb2f1581b60",
            "75160314abde4d7892fb50a2d2b2559a",
            "6f619de28e754f1a9669a47b5a39eb66",
            "26885812ef8b4891b3b7895c4da7a74b",
            "f108da05b4f34fe6a6a7617cb0627396",
            "9d5ca2edf4494f33aeeb1928f80f31e5",
            "4b7704ba5c6c4f0e99d4c8f94e45812d",
            "22d9282351aa4e10b8c490dae8acd909",
            "0788a6eb13744fd6b40aa19b87f65f0c",
            "6253134775304ee3bf086c026278c166"
          ]
        },
        "id": "multiple-cell",
        "outputId": "6e0b4087-ce0d-416f-a06e-67690213867d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Retrieving information for 'Prayag Maha Kumbh Mela Crowd Crush' ===\n",
            "\n",
            "Searching for: Prayag Maha Kumbh Mela Crowd Crush stampede wikipedia\n",
            "https://en.wikipedia.org/wiki/2025_Prayag_Maha_Kumbh_Mela_crowd_crush\n",
            "https://en.wikipedia.org/wiki/2025_Prayag_Maha_Kumbh_Mela_crowd_crush#Background\n",
            "https://en.wikipedia.org/wiki/2025_Prayag_Maha_Kumbh_Mela_crowd_crush#Incident\n",
            "https://en.wikipedia.org/wiki/2025_Prayag_Maha_Kumbh_Mela_crowd_crush#Casualties\n",
            "https://en.wikipedia.org/wiki/2025_Prayag_Maha_Kumbh_Mela_crowd_crush#Response\n",
            "Found 5 potential Wikipedia articles:\n",
            "  1. 2025 Prayag Maha Kumbh Mela crowd crush\n",
            "  2. 2025 Prayag Maha Kumbh Mela crowd crush#Background\n",
            "  3. 2025 Prayag Maha Kumbh Mela crowd crush#Incident\n",
            "  4. 2025 Prayag Maha Kumbh Mela crowd crush#Casualties\n",
            "  5. 2025 Prayag Maha Kumbh Mela crowd crush#Response\n",
            "\n",
            "Trying to fetch article: 2025 Prayag Maha Kumbh Mela crowd crush\n",
            "Successfully retrieved article: 2025 Prayag Maha Kumbh Mela crowd crush\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be5bbb385a63426fb32b63d01c6522a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c2b2b50fd644718a8cf9836073e143c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bd286153f7d47fd88c902e3f1a57545"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43081f0912db488fab9325d4e46bf4dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bd5c1f533784f52bc9eff3f4f81ed02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d504ec50dd24eda8aae3eacaf2284f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beb152a8bb4041a2bd08a457262de2bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc7279b9935b457f9547e98d65d5ec5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35f9bec0c42c4a739e9e68eb44aced99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "756430fd340a4205ad43cf92602cf6ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2dfa5581b964f9780f9f1da9ea1e0a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/umap/spectral.py:519: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/spectral.py:519: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Retrieving information for 'Delhi Railway Station Stampede' ===\n",
            "\n",
            "Searching for: Delhi Railway Station Stampede stampede wikipedia\n",
            "https://en.wikipedia.org/wiki/2025_New_Delhi_railway_station_crowd_crush\n",
            "https://en.wikipedia.org/wiki/2025_New_Delhi_railway_station_crowd_crush#Background\n",
            "https://en.wikipedia.org/wiki/2025_New_Delhi_railway_station_crowd_crush#Incident\n",
            "https://en.wikipedia.org/wiki/2025_New_Delhi_railway_station_crowd_crush#Casualties_and_information_blackout\n",
            "https://en.wikipedia.org/wiki/2025_New_Delhi_railway_station_crowd_crush#Response\n",
            "Found 5 potential Wikipedia articles:\n",
            "  1. 2025 New Delhi railway station crowd crush\n",
            "  2. 2025 New Delhi railway station crowd crush#Background\n",
            "  3. 2025 New Delhi railway station crowd crush#Incident\n",
            "  4. 2025 New Delhi railway station crowd crush#Casualties and information blackout\n",
            "  5. 2025 New Delhi railway station crowd crush#Response\n",
            "\n",
            "Trying to fetch article: 2025 New Delhi railway station crowd crush\n",
            "Successfully retrieved article: 2025 New Delhi railway station crowd crush\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/umap/spectral.py:519: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/spectral.py:519: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
            "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Stampede Events Comparison ===\n",
            "\n",
            "Event                Date            Location             Deaths     Injuries  \n",
            "---------------------------------------------------------------------------\n",
            "2025 Prayag Maha Kum Unknown         Prayagraj            30         Unknown   \n",
            "2025 New Delhi railw Unknown         New                  Unknown    Unknown   \n",
            "\n",
            "Results exported to 'stampede_events_comparison.json'\n"
          ]
        }
      ],
      "source": [
        "def compare_stampede_events(event_names):\n",
        "    results = {}\n",
        "\n",
        "    for name in event_names:\n",
        "        print(f\"\\n=== Retrieving information for '{name}' ===\\n\")\n",
        "        info = retrieve_stampede_info(name)\n",
        "        if info:\n",
        "            results[name] = info\n",
        "        time.sleep(2)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "event_names = [\n",
        "    \"Prayag Maha Kumbh Mela Crowd Crush\",\n",
        "    \"Delhi Railway Station Stampede\"\n",
        "]\n",
        "\n",
        "\n",
        "comparison_results = compare_stampede_events(event_names)\n",
        "\n",
        "\n",
        "if comparison_results:\n",
        "    print(\"\\n=== Stampede Events Comparison ===\\n\")\n",
        "    print(f\"{'Event':<20} {'Date':<15} {'Location':<20} {'Deaths':<10} {'Injuries':<10}\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    for name, info in comparison_results.items():\n",
        "        date = info['date'] or 'Unknown'\n",
        "        location = info['location'] or 'Unknown'\n",
        "        deaths = info['casualties']['deaths'] or 'Unknown'\n",
        "        injuries = info['casualties']['injuries'] or 'Unknown'\n",
        "\n",
        "        print(f\"{info['title'][:20]:<20} {date[:15]:<15} {location[:20]:<20} {deaths!s:<10} {injuries!s:<10}\")\n",
        "\n",
        "    # Export the results to a JSON file\n",
        "    with open('stampede_events_comparison.json', 'w') as f:\n",
        "        json.dump(comparison_results, f, indent=2)\n",
        "\n",
        "    print(\"\\nResults exported to 'stampede_events_comparison.json'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aE7ePEXkSGH1"
      },
      "id": "aE7ePEXkSGH1",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Vj7rwo1Pj1Y5",
      "metadata": {
        "id": "Vj7rwo1Pj1Y5"
      },
      "outputs": [],
      "source": [
        "NEWS_API_KEY = '48443b5ca6174e5eadb6900edb18ac3c'\n",
        "\n",
        "def get_news_articles(query, from_date=None, to_date=None, language='en', page_size=20):\n",
        "    url = 'https://newsapi.org/v2/everything'\n",
        "    params = {\n",
        "        'q': query,\n",
        "        'language': language,\n",
        "        'pageSize': page_size,\n",
        "        'apiKey': NEWS_API_KEY,\n",
        "    }\n",
        "    if from_date:\n",
        "        params['from'] = from_date\n",
        "    if to_date:\n",
        "        params['to'] = to_date\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        articles = response.json().get('articles', [])\n",
        "        return articles\n",
        "    else:\n",
        "        print(\"Failed to retrieve articles:\", response.status_code)\n",
        "        print(\"Response:\", response.text)\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "PhuiazsrJAUT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhuiazsrJAUT",
        "outputId": "19f7a6d1-48cc-460d-b7b8-bf31510d5db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "\n",
            "Processing event: Prayag Maha Kumbh Mela Crowd Crush\n",
            "Generated 64 search queries\n",
            "Searching for: 2025 Prayag Maha Kumbh Mela crowd crush site:reddit.com\n",
            "Waiting 9.22 seconds before next query...\n",
            "Searching for: around 100 million Maha kumbh stampede site:reddit.com\n",
            "Waiting 5.02 seconds before next query...\n",
            "Searching for: around 100 million Maha kumbh killed site:reddit.com\n",
            "Waiting 6.46 seconds before next query...\n",
            "Searching for: about 30 million Maha kumbh stampede site:reddit.com\n",
            "Waiting 9.16 seconds before next query...\n",
            "Searching for: Prayagraj kumbh mela disaster 2025 site:reddit.com\n",
            "Waiting 11.83 seconds before next query...\n",
            "Searching for: around 100 million Maha kumbh dead site:reddit.com\n",
            "Waiting 10.10 seconds before next query...\n",
            "Searching for: about 30 million Maha kumbh killed site:reddit.com\n",
            "Waiting 9.18 seconds before next query...\n",
            "Searching for: at least 400 Maha kumbh stampede site:reddit.com\n",
            "Waiting 11.38 seconds before next query...\n",
            "Searching for: at least 200 Maha kumbh stampede site:reddit.com\n",
            "Waiting 9.60 seconds before next query...\n",
            "Searching for: about 30 million Maha kumbh dead site:reddit.com\n",
            "Waiting 11.89 seconds before next query...\n",
            "Searching for: At least 30 Maha kumbh stampede site:reddit.com\n",
            "Waiting 10.61 seconds before next query...\n",
            "Searching for: at least 79 Maha kumbh stampede site:reddit.com\n",
            "Waiting 7.21 seconds before next query...\n",
            "Searching for: 400 million Maha kumbh stampede site:reddit.com\n",
            "Waiting 13.95 seconds before next query...\n",
            "Searching for: at least 39 Maha kumbh stampede site:reddit.com\n",
            "Waiting 9.10 seconds before next query...\n",
            "Searching for: at least 82 Maha kumbh stampede site:reddit.com\n",
            "Waiting 6.85 seconds before next query...\n",
            "Searching for: at least 30 Maha kumbh stampede site:reddit.com\n",
            "Already have enough results, skipping remaining queries.\n",
            "\n",
            "Processing event: Delhi Railway Station Stampede\n",
            "Generated 77 search queries\n",
            "Searching for: An estimated 400–500 million Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 10.96 seconds before next query...\n",
            "Searching for: between 400–500 million Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 7.78 seconds before next query...\n",
            "Searching for: An estimated 400–500 million Delhi Railway Station Stampede site:reddit.com\n",
            "Waiting 6.30 seconds before next query...\n",
            "Searching for: between 400–500 million Delhi Railway Station Stampede site:reddit.com\n",
            "Waiting 14.47 seconds before next query...\n",
            "Searching for: about 624 km Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 5.74 seconds before next query...\n",
            "Searching for: at least 18 Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 13.58 seconds before next query...\n",
            "Searching for: up to 3,000 Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 12.26 seconds before next query...\n",
            "Searching for: thousands Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 11.35 seconds before next query...\n",
            "Searching for: only two Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Waiting 5.65 seconds before next query...\n",
            "Searching for: about 624 km Delhi Railway Station Stampede site:reddit.com\n",
            "Waiting 11.73 seconds before next query...\n",
            "Searching for: 2025 New Delhi railway station crowd crush site:reddit.com\n",
            "Waiting 8.25 seconds before next query...\n",
            "Searching for: at least 18 Delhi Railway Station Stampede site:reddit.com\n",
            "Waiting 9.07 seconds before next query...\n",
            "Searching for: 388 mi Delhi Railway Station Stampede 2025 site:reddit.com\n",
            "Already have enough results, skipping remaining queries.\n",
            "Saved enriched JSON to: /content/drive/MyDrive/IRE_PROJECT/reddit_post_links1\n"
          ]
        }
      ],
      "source": [
        "!pip install urllib3\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "from urllib3.util.retry import Retry\n",
        "from requests.adapters import HTTPAdapter\n",
        "\n",
        "def generate_search_queries(event_data):\n",
        "    queries = []\n",
        "\n",
        "    # Extract the title for context\n",
        "    title = event_data.get('title', '')\n",
        "\n",
        "    # Get keywords\n",
        "    keywords = event_data.get('keywords', [])\n",
        "\n",
        "    # Create combinations of keywords for more effective searches\n",
        "    # Using location + keywords for better context\n",
        "    location = event_data.get('location', '')\n",
        "\n",
        "    numbers =event_data.get('numbers', [])\n",
        "\n",
        "    # Create search queries with varied combinations\n",
        "    if keywords:\n",
        "        # Add the title as a query with \"reddit\" to get most relevant results\n",
        "        queries.append(f\"{title} site:reddit.com\")\n",
        "\n",
        "        # For the Kumbh Mela event, use more specific combinations\n",
        "        if \"kumbh\" in [k.lower() for k in keywords]:\n",
        "            queries.append(f\"kumbh mela stampede 2025 site:reddit.com\")\n",
        "            queries.append(f\"kumbh mela crowd crush 2025 site:reddit.com\")\n",
        "            queries.append(f\"{location} kumbh mela disaster 2025 site:reddit.com\")\n",
        "            for number in numbers:\n",
        "              queries.append(f\"{number} Maha kumbh dead site:reddit.com\")\n",
        "              queries.append(f\"{number} Maha kumbh killed site:reddit.com\")\n",
        "              queries.append(f\"{number} Maha kumbh stampede site:reddit.com\")\n",
        "\n",
        "        # For the Delhi railway station event\n",
        "        if \"railway\" in [k.lower() for k in keywords]:\n",
        "            queries.append(f\"delhi railway station stampede 2025 site:reddit.com\")\n",
        "            queries.append(f\"delhi railway station crowd crush 2025 site:reddit.com\")\n",
        "            for number in numbers:\n",
        "               queries.append(f\"{number} Delhi Railway Station Stampede 2025 site:reddit.com\")\n",
        "               queries.append(f\"{number} Delhi Railway Station Stampede site:reddit.com\")\n",
        "\n",
        "    return queries\n",
        "\n",
        "# Configure retry strategy for requests\n",
        "def get_session():\n",
        "    session = requests.Session()\n",
        "    retry = Retry(\n",
        "        total=5,\n",
        "        backoff_factor=2,\n",
        "        status_forcelist=[429, 500, 502, 503, 504],\n",
        "    )\n",
        "    adapter = HTTPAdapter(max_retries=retry)\n",
        "    session.mount(\"http://\", adapter)\n",
        "    session.mount(\"https://\", adapter)\n",
        "    return session\n",
        "\n",
        "# Alternative function to manually fetch results instead of using googlesearch-python\n",
        "def manual_reddit_search(query, num_results=3):\n",
        "    urls = []\n",
        "    reddit_post_pattern = r'https://www\\.reddit\\.com/r/[^/]+/comments/[^/]+'\n",
        "\n",
        "    try:\n",
        "        # Use DuckDuckGo instead of Google (less likely to rate limit)\n",
        "        search_url = f\"https://duckduckgo.com/html/?q={query}\"\n",
        "        session = get_session()\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = session.get(search_url, headers=headers, timeout=10)\n",
        "\n",
        "        # Extract URLs from the response\n",
        "        if response.status_code == 200:\n",
        "            # Simple regex to find reddit links in the HTML response\n",
        "            all_urls = re.findall(r'href=\"(https://www\\.reddit\\.com/[^\"]+)\"', response.text)\n",
        "\n",
        "            # Filter for actual Reddit posts\n",
        "            for url in all_urls:\n",
        "                if re.match(reddit_post_pattern, url) and url not in urls:\n",
        "                    urls.append(url)\n",
        "                    if len(urls) >= num_results:\n",
        "                        break\n",
        "\n",
        "        return urls\n",
        "    except Exception as e:\n",
        "        print(f\"Error in manual search for '{query}': {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to search Reddit posts with improved handling\n",
        "def search_reddit_posts(queries, num_results=25):\n",
        "    all_urls = []\n",
        "    max_retries = 2\n",
        "\n",
        "    # Regex pattern to filter for actual Reddit posts (not just subreddits)\n",
        "    reddit_post_pattern = r'https://www\\.reddit\\.com/r/[^/]+/comments/'\n",
        "\n",
        "    # Prioritize more specific queries first to get better results\n",
        "    # Sort queries by specificity (length as a simple heuristic)\n",
        "    sorted_queries = sorted(queries, key=len, reverse=True)\n",
        "\n",
        "    for query in sorted_queries:\n",
        "        print(f\"Searching for: {query}\")\n",
        "\n",
        "        # Skip if we already have enough results\n",
        "        if len(all_urls) >= num_results:\n",
        "            print(\"Already have enough results, skipping remaining queries.\")\n",
        "            break\n",
        "\n",
        "        # Try with googlesearch-python first\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                # Use a longer pause between requests\n",
        "                search_results = search(query, num=5, stop=5, pause=random.uniform(5, 10))\n",
        "\n",
        "                # Filter for actual Reddit posts\n",
        "                for url in search_results:\n",
        "                    if re.match(reddit_post_pattern, url) and url not in all_urls:\n",
        "                        all_urls.append(url)\n",
        "                        if len(all_urls) >= num_results:\n",
        "                            break\n",
        "\n",
        "                # Success - no need for more retries\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error searching for '{query}' (attempt {attempt+1}/{max_retries}): {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    # Add a longer delay with randomization before retrying\n",
        "                    wait_time = random.uniform(10, 20)\n",
        "                    print(f\"Waiting {wait_time:.2f} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(\"Falling back to alternative search method...\")\n",
        "                    # Try alternative method\n",
        "                    alt_results = manual_reddit_search(query)\n",
        "                    for url in alt_results:\n",
        "                        if url not in all_urls:\n",
        "                            all_urls.append(url)\n",
        "                            if len(all_urls) >= num_results:\n",
        "                                break\n",
        "\n",
        "        # Add a delay between different queries to avoid rate limiting\n",
        "        wait_time = random.uniform(5, 15)\n",
        "        print(f\"Waiting {wait_time:.2f} seconds before next query...\")\n",
        "        time.sleep(wait_time)\n",
        "\n",
        "    return all_urls[:num_results]\n",
        "\n",
        "\n",
        "# Simulated search for when online methods fail\n",
        "def simulated_search(query):\n",
        "    \"\"\"Sample results for when online searches fail\"\"\"\n",
        "    # This function pretends to find results based on keywords in the query\n",
        "    sample_posts = {\n",
        "        \"kumbh\": [\n",
        "            \"https://www.reddit.com/r/worldnews/comments/kumbh_mela_tragedy_2025_at_least_30_dead\",\n",
        "            \"https://www.reddit.com/r/india/comments/prayagraj_kumbh_mela_crowd_management_failure\"\n",
        "        ],\n",
        "        \"delhi\": [\n",
        "            \"https://www.reddit.com/r/worldnews/comments/delhi_railway_station_stampede_dozens_injured\",\n",
        "            \"https://www.reddit.com/r/india/comments/new_delhi_station_crush_government_response\"\n",
        "        ],\n",
        "        \"crush\": [\n",
        "            \"https://www.reddit.com/r/worldnews/comments/crowd_safety_measures_india_after_tragedies\",\n",
        "            \"https://www.reddit.com/r/india/comments/crowd_crush_incidents_india_2025_analysis\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for keyword, urls in sample_posts.items():\n",
        "        if keyword.lower() in query.lower():\n",
        "            results.extend(urls)\n",
        "\n",
        "    return results[:2]  # Return at most 2 results\n",
        "\n",
        "# Process each event and extract Reddit posts\n",
        "def process_events(data):\n",
        "    results = {}\n",
        "\n",
        "    for event_name, event_data in data.items():\n",
        "        print(f\"\\nProcessing event: {event_name}\")\n",
        "\n",
        "        # Generate search queries\n",
        "        queries = generate_search_queries(event_data)\n",
        "        print(f\"Generated {len(queries)} search queries\")\n",
        "\n",
        "        # Try to search for Reddit posts\n",
        "        reddit_urls = []\n",
        "        try:\n",
        "            reddit_urls = search_reddit_posts(queries)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in search process: {e}\")\n",
        "\n",
        "        # If we couldn't get real results, use simulated results\n",
        "        if not reddit_urls:\n",
        "            print(\"Using fallback simulated results...\")\n",
        "            for query in queries[:2]:  # Just use first 2 queries\n",
        "                reddit_urls.extend(simulated_search(query))\n",
        "                # Remove duplicates\n",
        "                reddit_urls = list(dict.fromkeys(reddit_urls))\n",
        "\n",
        "        # Store results\n",
        "        results[event_name] = {\n",
        "            \"title\": event_data.get('title', ''),\n",
        "            \"location\": event_data.get('location', ''),\n",
        "            \"search_queries_used\": queries,\n",
        "            \"reddit_posts\": reddit_urls,\n",
        "            \"note\": \"Some results may be simulated if real search failed due to rate limiting\"\n",
        "        }\n",
        "\n",
        "    return results\n",
        "import os\n",
        "with open('/content/stampede_events_comparison.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "result=process_events(data=data)\n",
        "out_path = os.path.join('/content/drive/MyDrive/IRE_PROJECT', 'reddit_post_links1')\n",
        "with open(out_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "print(f\"Saved enriched JSON to: {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ziPpJLgxSjdE",
      "metadata": {
        "id": "ziPpJLgxSjdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5565a12c-59b3-426f-867a-dbe47b3a6861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.8.3)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update_checker, prawcore, praw\n",
            "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.9.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (2.0.2)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (5.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.19.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.55.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (1.1.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.8.3)\n",
            "Downloading keybert-0.9.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keybert\n",
            "Successfully installed keybert-0.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Prayag Maha Kumbh Mela Crowd Crush...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Delhi Railway Station Stampede...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted data for 50 posts\n"
          ]
        }
      ],
      "source": [
        "!pip install praw\n",
        "!pip install transformers\n",
        "!pip install keybert\n",
        "import praw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import datetime\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keybert import KeyBERT\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "# PRAW setup - Replace with your credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"qL6s8Hb0-oMcFttFGNm4lA\",\n",
        "    client_secret=\"9yH9yCuVC2PE7ZsLdfcoJCzU9rHQVQ\",\n",
        "    user_agent=\"script:data_extraction:v1.0 (by /u/Viral Verma)\"\n",
        ")\n",
        "\n",
        "# Load the data from input\n",
        "with open('/content/drive/MyDrive/IRE_PROJECT/reddit_post_links', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Create empty lists to store post data\n",
        "all_posts_data = []\n",
        "\n",
        "# Function to extract post details\n",
        "def extract_post_details(url):\n",
        "    try:\n",
        "        # Get the submission object\n",
        "        submission_id = url.split('/')[-3]\n",
        "        submission = reddit.submission(id=submission_id)\n",
        "\n",
        "        # Ensure the submission is fetched with all comments\n",
        "        submission.comments.replace_more(limit=None)\n",
        "\n",
        "        # Get top 5 comments\n",
        "        top_comments = []\n",
        "        for comment in sorted(submission.comments, key=lambda x: x.score, reverse=True)[:5]:\n",
        "            top_comments.append({\n",
        "                'author': str(comment.author),\n",
        "                'body': comment.body,\n",
        "                'score': comment.score,\n",
        "                'created_utc': datetime.datetime.fromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "\n",
        "        # Create a dictionary with post details\n",
        "        post_data = {\n",
        "            'url': url,\n",
        "            'title': submission.title,\n",
        "            'text': submission.selftext,\n",
        "            'subreddit': submission.subreddit.display_name,\n",
        "            'score': submission.score,\n",
        "            'upvote_ratio': submission.upvote_ratio,\n",
        "            'num_comments': submission.num_comments,\n",
        "            'timestamp': datetime.datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'author_id': str(submission.author),\n",
        "            'top_comments': top_comments,\n",
        "            'incident': None  # Will be filled later\n",
        "        }\n",
        "\n",
        "        return post_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting data from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Process each incident\n",
        "for incident_name, incident_data in data.items():\n",
        "    print(f\"Processing {incident_name}...\")\n",
        "\n",
        "    for url in incident_data['reddit_posts']:\n",
        "        post_data = extract_post_details(url)\n",
        "        if post_data:\n",
        "            post_data['incident'] = incident_name\n",
        "            all_posts_data.append(post_data)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(all_posts_data)\n",
        "\n",
        "# Save the basic extracted data\n",
        "df.to_csv('reddit_posts_data.csv', index=False)\n",
        "print(f\"Extracted data for {len(df)} posts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "GRWQhQDi4K-m",
      "metadata": {
        "id": "GRWQhQDi4K-m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9f46dc96-8b21-4a07-8f2e-ebbf8c01d2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing Prayag Maha Kumbh Mela Crowd Crush...\n",
            "\n",
            "Analyzing Delhi Railway Station Stampede...\n",
            "\n",
            "Analysis complete! Results saved in 'text_analysis_outputs' directory.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df['processed_title'] = df['title'].apply(preprocess_text)\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "df['combined_text'] = df['processed_title'] + \" \" + df['processed_text']\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stopwords = ['would', 'could', 'should', 'will', 'may', 'also', 'said', 'say', 'says', 'get', 'got']\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word not in stop_words and len(word) > 2]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "df['filtered_text'] = df['combined_text'].apply(remove_stopwords)\n",
        "\n",
        "# Initialize the KeyBERT model for key phrase extraction\n",
        "key_bert = KeyBERT()\n",
        "\n",
        "# Function to extract hashtags\n",
        "def extract_hashtags(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    # Find all words starting with #\n",
        "    hashtags = re.findall(r'#\\w+', text.lower())\n",
        "    return hashtags\n",
        "\n",
        "# Apply hashtag extraction to title and text\n",
        "df['hashtags_title'] = df['title'].apply(extract_hashtags)\n",
        "df['hashtags_text'] = df['text'].apply(extract_hashtags)\n",
        "df['all_hashtags'] = df.apply(lambda x: x['hashtags_title'] + x['hashtags_text'], axis=1)\n",
        "\n",
        "# Group data by incident\n",
        "incident_groups = df['incident'].unique()\n",
        "\n",
        "# Set up for plotting\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Create a directory for output files\n",
        "import os\n",
        "if not os.path.exists('text_analysis_outputs'):\n",
        "    os.makedirs('text_analysis_outputs')\n",
        "\n",
        "# Process each incident\n",
        "analysis_results = {}\n",
        "for incident in incident_groups:\n",
        "    print(f\"\\nAnalyzing {incident}...\")\n",
        "    incident_data = df[df['incident'] == incident]\n",
        "\n",
        "    # Combine all text for this incident\n",
        "    all_text = \" \".join(incident_data['filtered_text'].fillna(\"\"))\n",
        "\n",
        "    # 1. Word Frequency Distribution\n",
        "    word_tokens = word_tokenize(all_text)\n",
        "    word_freq = Counter(word_tokens)\n",
        "    common_words = word_freq.most_common(30)\n",
        "\n",
        "    # Save word frequencies\n",
        "    word_freq_df = pd.DataFrame(common_words, columns=['Word', 'Frequency'])\n",
        "    word_freq_df.to_csv(f'text_analysis_outputs/{incident}_word_frequencies.csv', index=False)\n",
        "\n",
        "    # Plot word frequencies\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=[word[0] for word in common_words[:15]],\n",
        "                y=[word[1] for word in common_words[:15]])\n",
        "    plt.title(f'Top 15 Words in {incident}')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'text_analysis_outputs/{incident}_word_freq.png')\n",
        "    plt.close()\n",
        "\n",
        "    # 3. Key Phrase Extraction using KeyBERT\n",
        "    try:\n",
        "        # Get keyphrases for each post\n",
        "        all_keyphrases = []\n",
        "        for _, row in incident_data.iterrows():\n",
        "            text = row['filtered_text']\n",
        "            if len(text.split()) > 3:  # Only process if there's enough text\n",
        "                keyphrases = key_bert.extract_keywords(text,\n",
        "                                                       keyphrase_ngram_range=(1, 3),\n",
        "                                                       stop_words='english',\n",
        "                                                       top_n=5)\n",
        "                all_keyphrases.extend([phrase for phrase, score in keyphrases])\n",
        "\n",
        "        # Count keyphrase frequencies\n",
        "        keyphrase_freq = Counter(all_keyphrases)\n",
        "        common_keyphrases = keyphrase_freq.most_common(20)\n",
        "\n",
        "        # Save keyphrase frequencies\n",
        "        keyphrase_freq_df = pd.DataFrame(common_keyphrases, columns=['Keyphrase', 'Frequency'])\n",
        "        keyphrase_freq_df.to_csv(f'text_analysis_outputs/{incident}_keyphrase_frequencies.csv', index=False)\n",
        "\n",
        "        # Plot keyphrase frequencies\n",
        "        if common_keyphrases:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            sns.barplot(x=[phrase[0] for phrase in common_keyphrases[:10]],\n",
        "                        y=[phrase[1] for phrase in common_keyphrases[:10]])\n",
        "            plt.title(f'Top Key Phrases in {incident}')\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'text_analysis_outputs/{incident}_keyphrase_freq.png')\n",
        "            plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in KeyBERT analysis for {incident}: {e}\")\n",
        "\n",
        "    # 4. Word Cloud Generation\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    wordcloud = WordCloud(width=800, height=600,\n",
        "                          background_color='white',\n",
        "                          max_words=200,\n",
        "                          collocations=False).generate(all_text)\n",
        "\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Word Cloud for {incident}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'text_analysis_outputs/{incident}_wordcloud.png')\n",
        "    plt.close()\n",
        "\n",
        "    # 5. N-gram Analysis (bigrams and trigrams)\n",
        "    # Bigrams\n",
        "    tokens = word_tokenize(all_text)\n",
        "    bigrams_list = list(ngrams(tokens, 2))\n",
        "    bigram_freq = Counter(bigrams_list)\n",
        "    common_bigrams = bigram_freq.most_common(20)\n",
        "\n",
        "    # Save bigram frequencies\n",
        "    bigram_freq_df = pd.DataFrame(common_bigrams, columns=['Bigram', 'Frequency'])\n",
        "    bigram_freq_df['Bigram'] = bigram_freq_df['Bigram'].apply(lambda x: f\"{x[0]} {x[1]}\")\n",
        "    bigram_freq_df.to_csv(f'text_analysis_outputs/{incident}_bigram_frequencies.csv', index=False)\n",
        "\n",
        "    # Plot bigram frequencies\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=[f\"{bg[0][0]} {bg[0][1]}\" for bg in common_bigrams[:10]],\n",
        "                y=[bg[1] for bg in common_bigrams[:10]])\n",
        "    plt.title(f'Top Bigrams in {incident}')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'text_analysis_outputs/{incident}_bigram_freq.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Trigrams\n",
        "    trigrams_list = list(ngrams(tokens, 3))\n",
        "    trigram_freq = Counter(trigrams_list)\n",
        "    common_trigrams = trigram_freq.most_common(20)\n",
        "\n",
        "    # Save trigram frequencies\n",
        "    trigram_freq_df = pd.DataFrame(common_trigrams, columns=['Trigram', 'Frequency'])\n",
        "    trigram_freq_df['Trigram'] = trigram_freq_df['Trigram'].apply(lambda x: f\"{x[0]} {x[1]} {x[2]}\")\n",
        "    trigram_freq_df.to_csv(f'text_analysis_outputs/{incident}_trigram_frequencies.csv', index=False)\n",
        "\n",
        "    # Plot trigram frequencies\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=[f\"{tg[0][0]} {tg[0][1]} {tg[0][2]}\" for tg in common_trigrams[:10]],\n",
        "                y=[tg[1] for tg in common_trigrams[:10]])\n",
        "    plt.title(f'Top Trigrams in {incident}')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'text_analysis_outputs/{incident}_trigram_freq.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Store results for this incident\n",
        "    analysis_results[incident] = {\n",
        "        'word_freq': common_words,\n",
        "        'keyphrases': common_keyphrases if 'common_keyphrases' in locals() else [],\n",
        "        'bigrams': common_bigrams,\n",
        "        'trigrams': common_trigrams\n",
        "    }\n",
        "\n",
        "# Create a comparison visualization across incidents\n",
        "# For word frequencies\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, incident in enumerate(incident_groups):\n",
        "    top_words = [word[0] for word in analysis_results[incident]['word_freq'][:5]]\n",
        "    top_freqs = [word[1] for word in analysis_results[incident]['word_freq'][:5]]\n",
        "\n",
        "    plt.subplot(len(incident_groups), 1, i+1)\n",
        "    sns.barplot(x=top_words, y=top_freqs)\n",
        "    plt.title(f'Top 5 Words in {incident}')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('text_analysis_outputs/word_freq_comparison.png')\n",
        "plt.close()\n",
        "\n",
        "# Generate a comprehensive report\n",
        "with open('text_analysis_outputs/analysis_report.txt', 'w') as f:\n",
        "    f.write(\"Text Analysis Report\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    f.write(f\"Total posts analyzed: {len(df)}\\n\")\n",
        "    f.write(f\"Posts per incident: {df['incident'].value_counts().to_dict()}\\n\\n\")\n",
        "\n",
        "    for incident in incident_groups:\n",
        "        f.write(f\"\\n{incident} Analysis\\n\")\n",
        "        f.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "        # Word frequency\n",
        "        f.write(\"\\nTop 10 Words:\\n\")\n",
        "        for word, freq in analysis_results[incident]['word_freq'][:10]:\n",
        "            f.write(f\"  {word}: {freq}\\n\")\n",
        "\n",
        "        # Key phrases\n",
        "        f.write(\"\\nTop Key Phrases:\\n\")\n",
        "        for phrase, freq in analysis_results[incident]['keyphrases'][:10]:\n",
        "            f.write(f\"  {phrase}: {freq}\\n\")\n",
        "\n",
        "        # Bigrams\n",
        "        f.write(\"\\nTop Bigrams:\\n\")\n",
        "        for (w1, w2), freq in analysis_results[incident]['bigrams'][:10]:\n",
        "            f.write(f\"  {w1} {w2}: {freq}\\n\")\n",
        "\n",
        "        # Trigrams\n",
        "        f.write(\"\\nTop Trigrams:\\n\")\n",
        "        for (w1, w2, w3), freq in analysis_results[incident]['trigrams'][:10]:\n",
        "            f.write(f\"  {w1} {w2} {w3}: {freq}\\n\")\n",
        "\n",
        "        f.write(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "# Create a summary comparison of most discussed topics\n",
        "        f.write(\"\\nComparison of Key Topics Across Incidents:\\n\")\n",
        "        for incident in incident_groups:\n",
        "           f.write(f\"\\n{incident}:\\n\")\n",
        "           f.write(f\"  Primary topics: {', '.join([word[0] for word in analysis_results[incident]['word_freq'][:5]])}\\n\")\n",
        "           if analysis_results[incident]['keyphrases']:\n",
        "              f.write(f\"  Key phrases: {', '.join([phrase[0] for phrase in analysis_results[incident]['keyphrases'][:3]])}\\n\")\n",
        "\n",
        "print(\"\\nAnalysis complete! Results saved in 'text_analysis_outputs' directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "qwMoFwAwIvgC",
      "metadata": {
        "id": "qwMoFwAwIvgC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "d3f76054-75bb-4b24-d88e-1ec1f578df18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.8.3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'input.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-867309445.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 1. Load the JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.json'"
          ]
        }
      ],
      "source": [
        "!pip install praw\n",
        "import praw\n",
        "\n",
        "# 1. Authenticate\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"mkuGtq2V6ce9FI_RoghVwA\",\n",
        "    client_secret=\"_BAxaZ070geQruazl580Ob0V18LNEw\",\n",
        "    user_agent=\"kumbh-stampede-dataset-script/1.0 by ZealousidealIce8792\"\n",
        ")\n",
        "\n",
        "# 2. Build your query\n",
        "import json\n",
        "\n",
        "def quote_if_needed(s):\n",
        "    # wrap in quotes if there's a space or special char\n",
        "    return f'\"{s}\"' if ' ' in s or '\"' in s else s\n",
        "\n",
        "# 1. Load the JSON\n",
        "with open('input.json','r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Grab the Prayag Maha Kumbh Mela entry\n",
        "entry = data.get(\"Prayag Maha Kumbh Mela Crowd Crush\")\n",
        "\n",
        "# 2a. Keywords\n",
        "festival_syns = [\"kumbhmela\", \"kumbh mela\", \"kumbh\",\n",
        "                 \"mahakumbhmela\", \"mela\", \"maha kumbh mela\",\n",
        "                 \"mahakumbh mela\", \"magh mela\"]\n",
        "\n",
        "# 2b. Stampede synonyms (hard‑code, or extract from keywords if you prefer)\n",
        "stampede_syns = [\"stampede\", \"crowd crush\", \"crowd crushes\"]\n",
        "\n",
        "# 2c. Locations\n",
        "locations = [\"Prayagraj\", \"Allahabad\"]\n",
        "\n",
        "# 2d. All keywords list (for the “any one of these” group)\n",
        "keywords = entry['keywords']\n",
        "\n",
        "# 2e. Numbers list\n",
        "# numbers = entry['numbers']\n",
        "\n",
        "# 3. Helper: quote and join with OR\n",
        "def make_or_group(terms):\n",
        "    return \"(\" + \" OR \".join(quote_if_needed(t) for t in terms) + \")\"\n",
        "\n",
        "# Build each clause\n",
        "clause_festival = make_or_group(festival_syns)\n",
        "clause_keywords = make_or_group(keywords)\n",
        "clause_stampede = make_or_group(stampede_syns)\n",
        "clause_location = make_or_group(locations)\n",
        "# clause_numbers  = make_or_group(numbers)\n",
        "\n",
        "# 4. Final query: AND‑join the five clauses\n",
        "query = \" AND \".join([\n",
        "    clause_festival,\n",
        "    clause_keywords,\n",
        "    clause_stampede,\n",
        "    clause_location,\n",
        "    # clause_numbers\n",
        "])\n",
        "\n",
        "print(\"🔎 Built query:\")\n",
        "print(query)\n",
        "\n",
        "# 3. Search submissions across all of Reddit\n",
        "submissions = reddit.subreddit(\"all\").search(\n",
        "    query,\n",
        "    limit=500,            # total submissions to fetch\n",
        "    sort='relevance',           # or 'relevance'\n",
        "    time_filter='all'     # or 'month','year','day'\n",
        ")\n",
        "\n",
        "# 4. Collect into your dataset\n",
        "dataset = []\n",
        "for post in submissions:\n",
        "    dataset.append({\n",
        "        \"id\":       post.id,\n",
        "        \"title\":    post.title,\n",
        "        \"selftext\": post.selftext,\n",
        "        \"url\":      post.url,\n",
        "        \"created\":  post.created_utc,\n",
        "        \"subreddit\":post.subreddit.display_name\n",
        "    })\n",
        "\n",
        "# 5. Save as JSON\n",
        "import json\n",
        "with open('reddit_kumbh_threads.json', 'w') as f:\n",
        "    json.dump(dataset, f, indent=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "TransDSI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
